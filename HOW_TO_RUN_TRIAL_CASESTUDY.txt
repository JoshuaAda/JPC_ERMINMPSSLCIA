The scripts are all configured, such that a simple trial case study can be run to see the LISCO approach in action.

The optimization problems generated are stored in folder "parametric_OP_data_trial".
The results are stored in folder "case_study_trial".

HOW TO RUN TRIAL CASE STUDY?
Paths:
- Ensure all paths and folder names in the scripts match your local setup before running.

Set up the environment:
- Install and activate required dependencies using the environment.yml file

Generate optimization problems:
- Run generate_OPs.py to create trial optimization problems

Configure and run experiments:
- For predictors:
- - Edit predictor_sweep_config.py to set desired parameters
- - Run predictor_sweep_config.py to generate configurations ("predictor_configs_trial.json")
- - Run training.py with sweep_config="predictor_configs_trial.json" to train predictor models

- For solvers without predictors:
- - Edit solver_no_pred_sweep_config.py to set desired parameters
- - Run solver_no_pred_sweep_config.py to generate configurations ("solver_no_pred_configs_trial.json")
- - Run training.py with sweep_config="solver_no_pred_configs_trial.json" to train solver models

- For solvers with predictors:
- - Edit solver_with_pred_sweep_config.py to set desired parameters
- - Run solver_with_pred_sweep_config.py to generate configurations ("solver_with_pred_configs_trial.json")
- - Run training.py with sweep_config="solver_with_pred_configs_trial.json" to train solver models

Evaluate the trained models:
- Run evaluation.py for each mode (predictor, solver_no_pred, solver_with_pred)
- This will generate detailed evaluation metrics and visualizations


The postprocessing.py file is specifically build to generate the tables and figures of the paper and is not used for the trial case study.